{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b35f870",
   "metadata": {},
   "source": [
    "# Import Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5412457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet as p\n",
    "import pybullet_data,gym,time,math\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a45f8",
   "metadata": {},
   "source": [
    "# Enviroments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e31d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(Currposition, endPosition): # [x,y,z]\n",
    "    distance_to_target = math.sqrt(math.pow(endPosition[0]-Currposition[0],2)+math.pow(endPosition[1]-Currposition[1],2)+math.pow(endPosition[2]-Currposition[2],2))\n",
    "    return distance_to_target\n",
    "\n",
    "class RexLeg:\n",
    "    def __init__(self, robot_id, leg_id, joints):\n",
    "        self.robot_id = robot_id\n",
    "        self.leg_id = leg_id\n",
    "        self.hip_joint, self.upper_joint, self.lower_joint = joints\n",
    "        self.joints = [self.hip_joint, self.upper_joint, self.lower_joint]\n",
    "\n",
    "    def set_pd_control(self, target_positions, kp=35, kd=1.0, max_force=45): #PD controller for some smoothing of motors\n",
    "        for joint, target_pos in zip(self.joints, target_positions):\n",
    "            pos, vel, _, _ = p.getJointState(self.robot_id, joint)\n",
    "            torque = kp * (target_pos - pos) - kd * vel\n",
    "            p.setJointMotorControl2(\n",
    "                bodyUniqueId=self.robot_id,\n",
    "                jointIndex=joint,\n",
    "                controlMode=p.TORQUE_CONTROL,\n",
    "                force=float(np.clip(torque, -max_force, max_force))\n",
    "            )\n",
    "class Rex:\n",
    "    def __init__(self, urdf_path, start_position,end_position):\n",
    "        self.robot_id = p.loadURDF(urdf_path, start_position)\n",
    "        self.num_joints = p.getNumJoints(self.robot_id)\n",
    "        self.legs = self.init_legs()\n",
    "        # Disable default motors set by urdf file \n",
    "        for j in range(self.num_joints):\n",
    "            p.setJointMotorControl2(\n",
    "                bodyIndex=self.robot_id,\n",
    "                jointIndex=j,\n",
    "                controlMode=p.VELOCITY_CONTROL,\n",
    "                force=0\n",
    "            )\n",
    "        self.start_pos  = start_position    # rex start position        (x,y,z)\n",
    "        self.end_pos    = end_position      # rexs desired end position (x,y,z)  \n",
    "\n",
    "    def init_legs(self):\n",
    "        leg_joint_map = {\n",
    "        0: [1, 2, 3],    # Front Right\n",
    "        1: [5, 6, 7],    # Front Left\n",
    "        2: [9, 10, 11],  # Rear Right\n",
    "        3: [13, 14, 15]  # Rear Left\n",
    "    }\n",
    "        return [RexLeg(self.robot_id, leg_id, indices)\n",
    "                for leg_id, indices in leg_joint_map.items()]\n",
    "\n",
    "    def get_observation(self):\n",
    "        obs = []\n",
    "        for leg in self.legs:\n",
    "            for joint in leg.joints:\n",
    "                pos, vel, _, _ = p.getJointState(self.robot_id, joint) # robots joints\n",
    "                obs.extend([pos, vel])\n",
    "\n",
    "        base_pos, base_orn = p.getBasePositionAndOrientation(self.robot_id) # base position (x,y,z)\n",
    "        base_lin_vel, base_ang_vel = p.getBaseVelocity(self.robot_id)       # base velocity (linear,angular (m/s))\n",
    "        obs.extend(base_pos)\n",
    "        obs.extend(base_lin_vel)\n",
    "        obs.extend(base_ang_vel)\n",
    "        return np.array(obs, dtype=np.float32)\n",
    "\n",
    "\n",
    "class QuadrupedEnv(gym.Env):\n",
    "    def __init__(self, render=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if render:\n",
    "            self.physics_client = p.connect(p.GUI)\n",
    "        else:\n",
    "            self.physics_client = p.connect(p.DIRECT) #set render false to disable gui\n",
    "\n",
    "        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "        p.setGravity(0, 0, -9.8)\n",
    "        self.time_step = 1 / 240\n",
    "        p.setTimeStep(self.time_step)\n",
    "\n",
    "        self.plane_id = p.loadURDF(\"plane.urdf\")\n",
    "        self.rex = Rex(\"aliengo/aliengo.urdf\", [0, 0, 0.45],[5,5,0.45])\n",
    "        self.counter = 0\n",
    "\n",
    "        obs_dim = len(self.rex.get_observation())\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "\n",
    "        # actionspace is 12 joints 3 per leg (4th is fixed)\n",
    "        self.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(12,), dtype=np.float32)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        self.counter += 1\n",
    "        base_pose = [0.0, 0.4, -0.6] # default pose for each leg [hip, upper, lower]\n",
    "\n",
    "        # split action into 4 legs Ã— 3 joints\n",
    "        action = np.clip(action, -1.0, 1.0).reshape(4, 3)\n",
    "        for leg, act in zip(self.rex.legs, action):\n",
    "            target_positions = [bp + 0.3 * a for bp, a in zip(base_pose, act)]\n",
    "            leg.set_pd_control(target_positions, kp=35, kd=1.0, max_force=45)\n",
    "\n",
    "        p.stepSimulation()\n",
    "        time.sleep(self.time_step)\n",
    "\n",
    "        obs = self.rex.get_observation() # observartion\n",
    "        base_pos, base_orn = p.getBasePositionAndOrientation(self.rex.robot_id) #reward\n",
    "        base_lin_vel, base_ang_vel = p.getBaseVelocity(self.rex.robot_id)       # base velocity (linear,angular (m/s))\n",
    "        forward_vel = base_lin_vel[0]\n",
    "        distance_to_target = calculate_distance(base_pos,self.rex.end_pos)\n",
    "\n",
    "\n",
    "        # Reward = height stability + orientation uprightness\n",
    "        height = base_pos[2]\n",
    "        roll, pitch, yaw = p.getEulerFromQuaternion(base_orn) # roll = sideways, ptich = forward/backward, yaw = left/right\n",
    "        up_vector = p.getMatrixFromQuaternion(base_orn)[6]  # z-vector\n",
    "        backward_penalty = max(0, -pitch)\n",
    "        forward_reward = 0.0\n",
    "        reward = 0.5*forward_reward+1.0 * height + 2.0 * up_vector + 0.8 *forward_vel - (5* distance_to_target) - 10*backward_penalty\n",
    "\n",
    "        done = height < 0.2 or pitch < -0.7 or pitch > 0.7 # did not walk or just felly fell\n",
    "        info = {}\n",
    "        return obs, reward, done, info\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        p.resetSimulation()\n",
    "        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "        p.setGravity(0, 0, -9.8)\n",
    "        p.setTimeStep(self.time_step)\n",
    "        self.plane_id = p.loadURDF(\"plane.urdf\")\n",
    "        self.rex = Rex(\"aliengo/aliengo.urdf\", [0, 0, 0.6],[5,5,0.45])\n",
    "        self.counter = 0\n",
    "        return self.rex.get_observation()\n",
    "\n",
    "    def close(self):\n",
    "        p.disconnect(self.physics_client) # stop rex forever :(\n",
    "\n",
    "def make_env(rank=0, seed=0):\n",
    "    def _init():\n",
    "        env = QuadrupedEnv(render=False)\n",
    "        return env\n",
    "    return _init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab7d08",
   "metadata": {},
   "source": [
    "# Model Training Phase\n",
    "## Standing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80700efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_enviroments = 16 \n",
    "    if (num_enviroments > 1 ):\n",
    "        env = DummyVecEnv([make_env(i) for i in range(num_enviroments)])\n",
    "    else:   \n",
    "        env = QuadrupedEnv(render=True)\n",
    "\n",
    "    ppo_model = PPO(\"MlpPolicy\", env, verbose=2)\n",
    "    ppo_model.learn(total_timesteps=100000,progress_bar=True)\n",
    "    ppo_model.save(\"ppo_standing2_rex\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7614fefa",
   "metadata": {},
   "source": [
    "# Agent Enviroment Test\n",
    "## Stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_model = PPO.load(\"ppo_standing_rex.zip\")\n",
    "env = QuadrupedEnv(render=True)\n",
    "obs = env.reset()\n",
    "for _ in range(10000):\n",
    "    action,_ = ppo_model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
